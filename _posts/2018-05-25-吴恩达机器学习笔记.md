---
layout: post
title: "吴恩达机器学习笔记"
date: 2018-05-25
categories: 机器学习 Python
tags: 机器学习 Python
author: Quan Zhang
---

* content
{:toc}

## 引言

### 无监督学习

#### 回归问题

对于房价的预测，可以采用直线拟合和二次方程拟合等方式，离散数据拟合为连续数据，是属于回归问题。

![](/images/blog/20180525/1.jpg)

#### 分类问题

对于判断肿瘤是否为良性，良性为0，恶性为1，或者良性为0，还有1类恶性，2类恶性，3类恶性等等，这属于分类问题。

![](/images/blog/20180525/2.jpg)

#### SVM支持向量机

在其他一些机器学习问题中，可能会遇到不止一种特征。举个例子，我们不仅知道肿瘤的尺寸，还知道对应患者的年龄。在其他机器学习问题中，我们通常有更多的特征，比如肿块的密度、肿瘤细胞的尺寸的一致性和形状的一致性等等。

这类多特征的问题可以用SVM支持向量机来处理。

![](/images/blog/20180525/3.jpg)

### 无监督学习

监督学习的数据集都已经被标明是阴性或阳性。所以对监督学习里的每条数据，我们已经清楚地知道，训练集对应的正确答案。然而，在无监督学习中没有任何标签。

![](/images/blog/20180525/4.jpg)

![](/images/blog/20180525/5.jpg)

针对数据集，无监督学习就能判断出数据有两个不同的聚集簇，这种算法叫做聚类算法。

## 单变量线性回归

### 模型表示

单变量线性回归，即Linear Regression with One Variable。

我们将用来描述回归问题的变量定义如下：

- $m$代表训练集中实例的数量
- $x$代表特征/输入变量
- $y$代表目标变量/输出变量
- $(x,y)$代表训练集中的实例
- $(x^{(i)},y^{(i)})$代表第$i$个观察实例
- $h$代表学习算法的解决方案或假设模型

因为只含有一个特征/输入变量，所以单变量线性回归问题可表示为：

<center>\[h_{\theta}(x)=\theta_{0}+\theta_{1}x\]</center>

### 代价函数



