---
layout: post
title: "深度学习笔记"
date: 2018-06-02
categories: 机器学习 Python
tags: 机器学习 Python
author: Quan Zhang
---

* content
{:toc}

## 神经网络的编程基础

### 二分类

假如有一张图片作为输入，比如一只猫，如果识别这张图为猫，则输出标签1，否则为0。

这张图片需要保存3个矩阵，对应RGB三个颜色。把这些像素值提取出来，放到一个特征向量x中，x为列向量。

符号定义：

- $x$：表示一个$n_x$维数据，为输入数据，维度为($n_x$,1)
- y：表示输出结果，取值0和1
- ($x^{(i)},y^{(i)}$)：表示第$i$组数据，训练数据(默认)或者测试数据
- $X=[x^{(1)},x^{(2)}...x^{(m)}]$：表示输入，$n_x*m$维矩阵，$m$为样本数目
- $Y=[y^{(1)},y^{(2)}...y^{(m)}]$：表示输出，$1*m$维，一行一列

执行X.shape，则输出($n_x,m$)，Y.shape，则输出($1,m$)。

![](/images/blog/20180602/1.jpg)

### 向量化

向量化可以避免使用for循环，可以加速程序运行：$z=np.dot(w,x)+b$。for循环执行时间可能比向量化慢300倍。

### 激活函数

1. sigmoid函数$\frac{1}{1+e^{-z}}$：除了输出层是一个二分类问题基本不会用它

2. tanh函数$\frac{e^z-e^{-z}}{e^z+e^{-z}}$：非常优秀，几乎适合所有场合

3. Relu函数$max(0,z)$：常用的默认函数

### 激活函数的导数

1. sigmoid：$d(g(z))=g(z)(1-g(z))$

2. tanh：$d(g(z))=1-(tanh(z))^2$

3. Relu：

<center>\[d(g(z))=\begin{cases}
& 0 \text { if } z<0\\ 
& 1 \text{ if } z>0\\
& ? \text { if } z=0 
\end{cases}\]</center>

